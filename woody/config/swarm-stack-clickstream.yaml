version: "3.4"

services:
  aggregator:
    image: zlynch/clickstream:1.0
    hostname: clickstream-aggregator
    networks:
      - zk-net
    environment:
      PYTHONPATH: /opt/woody
      # outside cluster: 192.168.70.220,192.168.70.189,192.168.70.35
      #                  17001
      CASSANDRA_SERVERS: cass1,cass2,cass3
      CASSANDRA_PORT: 9042
      CASSANDRA_USER: dev
      CASSANDRA_PASS: dcb5c69fedb78e9a29a3
      # outside cluster: 192.168.70.220:17812,192.168.70.35:17812,192.168.70.94:17812
      KAFKA_BROKERS: k1:17812,k2:17812,k3:17812
      SPARK_HOME: /opt/spark
      #SPARK_MASTER: spark://spark1:7077
      SPARK_SCHED_MODE: FAIR
      SPARK_SCHED_POOL: clickstream
      SPARK_SCHED_FILE: /opt/spark/conf/fairscheduler.xml
      SPARK_LOCAL_DIRS: /data
      PYSPARK_MAJOR_PYTHON_VERSION: 3
    ports:
      - published: 18881
        target: 4040
        mode: host
        #command: /opt/spark/bin/spark-submit --master spark://spark1:7077 --jars /opt/spark-extern/spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar woody/apps/clickstream.py
    volumes:
       - /fedev-data/spark-conf:/data/spark-conf
       - /fedev-data:/data
#      - /etc/kubernetes:/etc/kubernetes
#      - /spark-cluster:/var/run/secrets/kubernetes.io/serviceaccount
    #--master k8s://https://192.168.70.140:6443
    #--master spark://spark1:7077
    #--conf spark.kubernetes.container.image=zlynch/spark:2.4.0
    #--conf spark.kubernetes.container.image=kubespark/spark-driver:v2.2.0-kubernetes-0.5.0
    #--conf spark.kubernetes.authenticate.submission.oauthToken=spark-token-c4kpx
    #--conf spark.kubernetes.authenticate.driver.oauthToken=spark-token-c4kpx
    #--conf spark.kubernetes.driver.container.image=kubespark/spark-driver-py:v2.2.0-kubernetes-0.5.0
    #--conf spark.kubernetes.executor.container.image=kubespark/spark-executor-py:v2.2.0-kubernetes-0.5.0
    command: "/opt/spark/bin/spark-submit 
    --packages com.datastax.spark:spark-cassandra-connector_2.11:2.4.0
    --master k8s://http://192.168.70.140:8080
    --deploy-mode cluster
    --conf spark.executor.instances=1
    --conf spark.kubernetes.container.image=zlynch/spark-kube:1.0
    --conf spark.kubernetes.driver.pod.name=spark-drv-clickstream
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark
    --conf spark.kubernetes.driver.secrets.spark-secret=/data/spark-conf/secrets
    --conf spark.kubernetes.executor.secrets.spark-secret=/data/spark-conf/secrets
    --conf spark.cassandra.connection.host=cass1,cass2,cass3
    --conf spark.cassandra.connection.port=9042
    --conf spark.cassandra.input.consistency.level=ONE
    --conf spark.cassandra.output.consistency.level=ONE
    --jars /opt/spark-extern/spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar
    woody/apps/clickstream.py"
    deploy:
      placement:
        constraints: [node.labels.kfknode == 2]
  producer:
    image: zlynch/clickstream-producer:1.0
    hostname: clickstream-producer
    networks:
      - zk-net
    # outside cluster: 192.168.70.220:17812,192.168.70.35:17812,192.168.70.94:17812
    volumes:
      - /fedev-data/yoochoose:/data/yoochoose
      - /tmp:/tmp
    command: build/click_producer -alsologtostderr -brokers k1:17812,k2:17812,k3:17812
    deploy:
      placement:
        constraints: [node.labels.kfknode == 2]
      replicas: 1

networks:
  zk-net:
    external:
      name: kfk_zk-net
