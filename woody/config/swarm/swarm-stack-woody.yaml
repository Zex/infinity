version: "3.4"

services:
  checkin_aggregator:
    image: zlynch/checkin-stream:1.1
    hostname: checkin-stream-aggregator
    networks:
      - zk-net
    environment:
      PYTHONPATH: /opt/woody
      TZ: Asia/Hong_Kong
      CASSANDRA_SERVERS: 192.168.70.220,192.168.70.203,192.168.70.35
      CASSANDRA_PORT: 17001
      CASSANDRA_USER: dev
      CASSANDRA_PASS: dcb5c69fedb78e9a29a3
      # outside cluster: 192.168.70.220:17812,192.168.70.35:17812,192.168.70.94:17812
      KAFKA_BROKERS: k1:17812,k2:17812,k3:17812
      SPARK_HOME: /opt/spark
      SPARK_SCHED_MODE: FAIR
      SPARK_SCHED_POOL: checkin-stream
      SPARK_SCHED_FILE: /opt/spark/conf/fairscheduler.xml
      SPARK_LOCAL_DIRS: /data
      SPARK_EXTRA_CLASSPATH: /opt/spark-extern
    command: "/opt/spark/bin/spark-submit 
    --name checkin-stream-aggregator
    --master k8s://https://192.168.70.140:6443
    --deploy-mode cluster
    --conf spark.scheduler.mode=FAIR
    --conf spark.app.name=checkin-stream-aggregator
    --conf spark.executor.instances=2
    --conf spark.kubernetes.authenticate.submission.caCertFile=/opt/woody/config/kube/pki/ca.crt
    --conf spark.kubernetes.authenticate.driver.caCertFile=/opt/woody/config/kube/pki/ca.crt
    --conf spark.kubernetes.authenticate.submission.clientCertFile=/opt/woody/config/kube/pki/apiserver-kubelet-client.crt
    --conf spark.kubernetes.authenticate.submission.clientKeyFile=/opt/woody/config/kube/pki/apiserver-kubelet-client.key
    --conf spark.kubernetes.authenticate.driver.clientKeyFile=/opt/woody/config/kube/pki/apiserver-kubelet-client.key
    --conf spark.kubernetes.authenticate.driver.clientCertFile=/opt/woody/config/kube/pki/apiserver-kubelet-client.crt
    --conf spark.kubernetes.namespace=default
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark
    --conf spark.kubernetes.submission.waitAppCompletion=true
    --conf spark.kubernetes.container.image=zlynch/checkin-stream:1.1
    --conf spark.kubernetes.container.image.pullPolicy=Always
    --conf spark.kubernetes.driverEnv.SPARK_LOCAL_IP=localhost
    --conf spark.kubernetes.driverEnv.SPARK_SCHED_FILE=/tmp/fairscheduler.xml
    --conf spark.kubernetes.driverEnv.SPARK_EXTRA_CLASSPATH=/opt/spark-extern
    --conf spark.kubernetes.driverEnv.KAFKA_BROKERS=192.168.70.220:17812,192.168.70.35:17812,192.168.70.94:17812
    --conf spark.kubernetes.driverEnv.CASSANDRA_SERVERS=192.168.70.220
    --conf spark.kubernetes.driverEnv.CASSANDRA_PORT=17001
    --conf spark.kubernetes.driverEnv.CASSANDRA_USER=dev
    --conf spark.kubernetes.driverEnv.CASSANDRA_PASS=dcb5c69fedb78e9a29a3
    --conf spark.cassandra.connection.host=192.168.70.203
    --conf spark.cassandra.connection.port=17001
    --conf spark.cassandra.input.consistency.level=ONE
    --conf spark.cassandra.output.consistency.level=ONE
    --conf spark.streaming.kafka.maxRetries=100
    --conf spark.streaming.stopGracefullyOnShutdown=true
    --conf spark.kubernetes.pyspark.pythonVersion=3
    --properties-file /opt/spark/conf/spark-defaults.conf
    --packages com.datastax.spark:spark-cassandra-connector_2.11:2.4.0
    --jars /opt/spark-extern/spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar
    -v
    woody/apps/user_profile.py"
    deploy:
      placement:
        constraints: [node.labels.kfknode == 2]
      replicas: 1

  checkin_producer:
    image: zlynch/woody-bg:1.1
    hostname: checkin-stream-producer
    networks:
      - zk-net
    # outside cluster: 192.168.70.220:17812,192.168.70.35:17812,192.168.70.94:17812
    environment:
      TZ: Asia/Hong_Kong
    volumes:
      - /fedev-data/foursquare:/data/foursquare
    command: build/checkin_producer -brokers k1:17812,k2:17812,k3:17812
    deploy:
      placement:
        constraints: [node.labels.sparknode == 1]
      replicas: 1

  clickstream_aggregator:
    image: zlynch/clickstream:1.1
    hostname: clickstream-aggregator
    networks:
      - zk-net
    environment:
      PYTHONPATH: /opt/woody
      TZ: Asia/Hong_Kong
      # outside cluster: 192.168.70.220,192.168.70.203,192.168.70.35
      #                  17001
#      CASSANDRA_SERVERS: cass1,cass2,cass3
#      CASSANDRA_PORT: 9042
      CASSANDRA_SERVERS: 192.168.70.220,192.168.70.203,192.168.70.35
      CASSANDRA_PORT: 17001
      CASSANDRA_USER: dev
      CASSANDRA_PASS: dcb5c69fedb78e9a29a3
      # outside cluster: 192.168.70.220:17812,192.168.70.35:17812,192.168.70.94:17812
      KAFKA_BROKERS: k1:17812,k2:17812,k3:17812
      SPARK_HOME: /opt/spark
      #SPARK_MASTER: spark://spark1:7077
      SPARK_SCHED_MODE: FAIR
      SPARK_SCHED_POOL: clickstream
      SPARK_SCHED_FILE: /opt/spark/conf/fairscheduler.xml
      SPARK_LOCAL_DIRS: /data
      SPARK_EXTRA_CLASSPATH: /opt/spark-extern
#      PYSPARK_MAJOR_PYTHON_VERSION: 3
#    ports:
#      - published: 18881
#        target: 4040
#        mode: host
#    --packages com.datastax.spark:spark-cassandra-connector_2.11:2.4.0
#    --jars /opt/spark-extern/spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar 
#    --deploy-mode: cluster
#    --conf spark.scheduler.mode=FAIR
#    --master spark://spark1:7077
#    --jars /opt/spark-extern/spark-*jar
#    --jars /opt/spark-extern/spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar,/opt/spark-extern/spark-cassandra-connector-2.4.0-s_2.11.jar
#    --conf spark.kubernetes.driver.pod.name=spark-drv-clickstream
    command: "/opt/spark/bin/spark-submit 
    --name clickstream-aggregator
    --master k8s://https://192.168.70.140:6443
    --deploy-mode cluster
    --conf spark.scheduler.mode=FAIR
    --conf spark.app.name=clickstream-aggregator
    --conf spark.executor.instances=2
    --conf spark.kubernetes.authenticate.submission.caCertFile=/opt/woody/config/kube/pki/ca.crt
    --conf spark.kubernetes.authenticate.driver.caCertFile=/opt/woody/config/kube/pki/ca.crt
    --conf spark.kubernetes.authenticate.submission.clientCertFile=/opt/woody/config/kube/pki/apiserver-kubelet-client.crt
    --conf spark.kubernetes.authenticate.submission.clientKeyFile=/opt/woody/config/kube/pki/apiserver-kubelet-client.key
    --conf spark.kubernetes.authenticate.driver.clientKeyFile=/opt/woody/config/kube/pki/apiserver-kubelet-client.key
    --conf spark.kubernetes.authenticate.driver.clientCertFile=/opt/woody/config/kube/pki/apiserver-kubelet-client.crt
    --conf spark.kubernetes.namespace=default
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark
    --conf spark.kubernetes.submission.waitAppCompletion=true
    --conf spark.kubernetes.container.image=zlynch/clickstream:1.1
    --conf spark.kubernetes.container.image.pullPolicy=Always
    --conf spark.kubernetes.driverEnv.SPARK_LOCAL_IP=localhost
    --conf spark.kubernetes.driverEnv.SPARK_SCHED_FILE=/tmp/fairscheduler.xml
    --conf spark.kubernetes.driverEnv.SPARK_EXTRA_CLASSPATH=/opt/spark-extern
    --conf spark.kubernetes.driverEnv.KAFKA_BROKERS=192.168.70.220:17812,192.168.70.35:17812,192.168.70.94:17812
    --conf spark.kubernetes.driverEnv.CASSANDRA_SERVERS=192.168.70.220
    --conf spark.kubernetes.driverEnv.CASSANDRA_PORT=17001
    --conf spark.kubernetes.driverEnv.CASSANDRA_USER=dev
    --conf spark.kubernetes.driverEnv.CASSANDRA_PASS=dcb5c69fedb78e9a29a3
    --conf spark.cassandra.connection.host=192.168.70.203
    --conf spark.cassandra.connection.port=17001
    --conf spark.cassandra.input.consistency.level=ONE
    --conf spark.cassandra.output.consistency.level=ONE
    --conf spark.streaming.kafka.maxRetries=100
    --conf spark.streaming.stopGracefullyOnShutdown=true
    --conf spark.kubernetes.pyspark.pythonVersion=3
    --properties-file /opt/spark/conf/spark-defaults.conf
    --packages com.datastax.spark:spark-cassandra-connector_2.11:2.4.0
    --jars /opt/spark-extern/spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar
    -v
    woody/apps/clickstream.py"
    deploy:
      placement:
        constraints: [node.labels.kfknode == 2]
      replicas: 0

  clickstream_producer:
    image: zlynch/woody-bg:1.0
    hostname: clickstream-producer
    networks:
      - zk-net
    # outside cluster: 192.168.70.220:17812,192.168.70.35:17812,192.168.70.94:17812
    environment:
      TZ: Asia/Hong_Kong
    volumes:
      - /fedev-data/yoochoose:/data/yoochoose
    command: build/click_producer -brokers k1:17812,k2:17812,k3:17812
    deploy:
      placement:
        constraints: [node.labels.sparknode == 1]
      replicas: 0

  apiserver:
    image: zlynch/woody-bg:1.1
    hostname: apiserver
    networks:
      - zk-net
    ports:
      - published: 17483
        target: 17483
        mode: host
    environment:
      TZ: Asia/Hong_Kong
    volumes: # temp vehicle metrics
      - /fedev-data/vehicle:/data/vehicle
    command: "build/apiserver
    -cass cass1,cass2,cass3
    -cass_port 9042 
    -apiaddr :17483
    -origins http://192.168.70.203:*,http://apiserver:*
    -cass_user dev
    -cass_pass dcb5c69fedb78e9a29a3"
    deploy:
      replicas: 1
      placement:
        constraints: [node.labels.sparknode == 1]
  ui:
    image: zlynch/woody-ui:1.1
    hostname: ui
    depends_on:
      - apiserver
    networks:
      - zk-net
    environment:
      TZ: Asia/Hong_Kong
    ports:
      - published: 17484
        target: 80
        mode: host
    deploy:
      placement:
        constraints: [node.labels.sparknode == 1]
      replicas: 1

networks:
  zk-net:
    external:
      name: kfk_zk-net
