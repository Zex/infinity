#FROM zlynch/spark:2.4.0
FROM zlynch/spark-kube-py:1.0

ENV SPARK_VERSION=2.4.0
ENV HADOOP_VERSION=2.7
ENV SPARK_HOME=/opt/spark
ENV SCALA_VERSION=2.11
ENV SPARK_EXTERN=/opt/spark-extern

ENV WOODY_ROOT /opt/woody
ENV PYTHONPATH $WOODY_ROOT:$PYTHONPATH
WORKDIR $WOODY_ROOT

COPY Makefile requirements.txt $WOODY_ROOT/
COPY woody $WOODY_ROOT/woody 
COPY config $WOODY_ROOT/config
COPY scripts $WOODY_ROOT/scripts

RUN echo $PYTHONPATH && apk add curl && \
  mkdir -p ${SPARK_EXTERN} && curl "https://search.maven.org/remotecontent?filepath=org/apache/spark/spark-streaming-kafka-0-8-assembly_${SCALA_VERSION}/${SPARK_VERSION}/spark-streaming-kafka-0-8-assembly_${SCALA_VERSION}-${SPARK_VERSION}.jar" -o ${SPARK_EXTERN}/spark-streaming-kafka-0-8-assembly_${SCALA_VERSION}-${SPARK_VERSION}.jar &&\
  curl "http://dl.bintray.com/spark-packages/maven/datastax/spark-cassandra-connector/${SPARK_VERSION}-s_${SCALA_VERSION}/spark-cassandra-connector-${SPARK_VERSION}-s_${SCALA_VERSION}.jar" -o ${SPARK_EXTERN}/spark-cassandra-connector-${SPARK_VERSION}-s_${SCALA_VERSION}.jar

RUN mkdir -p /opt/spark/conf && echo "<?xml version=\"1.0\"?> \
<allocations> \
  <pool name=\"production\"> \
    <schedulingMode>FAIR</schedulingMode> \
    <weight>2</weight> \
    <minShare>1</minShare> \
  </pool> \
  <pool name=\"dev\"> \
    <schedulingMode>FAIR</schedulingMode> \
    <weight>2</weight> \
    <minShare>1</minShare> \
  </pool> \
  <pool name=\"clickstream\"> \
    <schedulingMode>FAIR</schedulingMode> \
    <weight>3</weight> \
    <minShare>1</minShare> \
  </pool> \
</allocations>" > /opt/spark/conf/fairscheduler.xml

CMD ["scripts/aggr_cli.sh"]
