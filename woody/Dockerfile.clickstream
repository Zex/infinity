#FROM zlynch/spark:2.4.0
FROM zlynch/spark-kube-py:1.0

ENV TZ='Asia/Hong_Kong'
ENV SPARK_VERSION=2.4.0
ENV HADOOP_VERSION=2.7
ENV SPARK_HOME=/opt/spark
ENV SCALA_VERSION=2.11
#ENV SPARK_EXTRA_CLASSPATH=/opt/spark/jars
ENV SPARK_EXTRA_CLASSPATH=/opt/spark-extern

ENV WOODY_ROOT /opt/woody
ENV PYTHONPATH $WOODY_ROOT:$PYTHONPATH
WORKDIR $WOODY_ROOT

COPY Makefile requirements.txt $WOODY_ROOT/
COPY woody $WOODY_ROOT/woody 
COPY config $WOODY_ROOT/config
COPY scripts $WOODY_ROOT/scripts
COPY \
 spark_extern/com.datastax.spark_spark-cassandra-connector_2.11-2.4.0.jar\
 spark_extern/commons-beanutils_commons-beanutils-1.9.3.jar\
 spark_extern/commons-collections_commons-collections-3.2.2.jar\
 spark_extern/com.twitter_jsr166e-1.1.0.jar\
 spark_extern/io.netty_netty-all-4.0.33.Final.jar\
 spark_extern/joda-time_joda-time-2.3.jar\
 spark_extern/org.joda_joda-convert-1.2.jar\
 spark_extern/org.scala-lang_scala-reflect-2.11.12.jar\
 /root/.ivy2/jars/

#RUN dnf install -y curl && \
RUN apk add --no-cache curl && \
  mkdir -p ${SPARK_EXTRA_CLASSPATH} && curl "https://search.maven.org/remotecontent?filepath=org/apache/spark/spark-streaming-kafka-0-8-assembly_${SCALA_VERSION}/${SPARK_VERSION}/spark-streaming-kafka-0-8-assembly_${SCALA_VERSION}-${SPARK_VERSION}.jar" -o ${SPARK_EXTRA_CLASSPATH}/spark-streaming-kafka-0-8-assembly_${SCALA_VERSION}-${SPARK_VERSION}.jar 
#curl "http://dl.bintray.com/spark-packages/maven/datastax/spark-cassandra-connector/${SPARK_VERSION}-s_${SCALA_VERSION}/spark-cassandra-connector-${SPARK_VERSION}-s_${SCALA_VERSION}.jar" -o ${SPARK_EXTRA_CLASSPATH}/spark-cassandra-connector-${SPARK_VERSION}-s_${SCALA_VERSION}.jar

ENV SPARK_DEFAULT_CONF=/opt/spark/conf/spark-defaults.conf

RUN mkdir -p /opt/spark/conf && echo "<?xml version=\"1.0\"?> \
<allocations> \
  <pool name=\"production\"> \
    <schedulingMode>FAIR</schedulingMode> \
    <weight>2</weight> \
    <minShare>1</minShare> \
  </pool> \
  <pool name=\"dev\"> \
    <schedulingMode>FAIR</schedulingMode> \
    <weight>2</weight> \
    <minShare>1</minShare> \
  </pool> \
  <pool name=\"clickstream\"> \
    <schedulingMode>FAIR</schedulingMode> \
    <weight>3</weight> \
    <minShare>1</minShare> \
  </pool> \
</allocations>" > ${SPARK_EXTRA_CLASSPATH}/fairscheduler.xml && \
echo "spark.scheduler.mode		     FAIR" >> ${SPARK_DEFAULT_CONF} && \
echo "spark.scheduler.pool		     clickstream" >> ${SPARK_DEFAULT_CONF} && \
echo "spark.executor.logs.rolling.maxSize	10000" >> ${SPARK_DEFAULT_CONF} && \
echo "nameserver 10.244.0.10" >> /etc/resolv.conf
#echo "spark.scheduler.allocation.file		 fairscheduler.xml" >> ${SPARK_DEFAULT_CONF} && \
#echo "spark.driver.extraClassPath        /opt/spark-extern" >> ${SPARK_DEFAULT_CONF} && \
#echo "spark.executor.extraClassPath	     /opt/spark-extern" >> ${SPARK_DEFAULT_CONF} && \
